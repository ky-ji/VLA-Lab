import streamlit as st
import json
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.gridspec import GridSpec
from pathlib import Path
import sys
import base64
import cv2

# --- è·¯å¾„é…ç½® ---
sys.path.insert(0, str(Path(__file__).parent.parent))
try:
    from toolbox.mpl_fonts import setup_matplotlib_fonts
    setup_matplotlib_fonts(verbose=False)
except Exception:
    pass

class InferenceGUI:
    def __init__(self, log_path):
        self.log_path = log_path
        self.valid = False
        self.load_data()
    
    def _get_latency_ms(self, timing_dict, key_base):
        """
        å®‰å…¨åœ°è·å–æ—¶å»¶å€¼ï¼ˆå…¼å®¹æ–°æ—§æ ¼å¼ï¼‰
        
        Args:
            timing_dict: æ—¶é—´ä¿¡æ¯å­—å…¸
            key_base: å­—æ®µååŸºç¡€ï¼ˆå¦‚ 'transport_latency'ï¼‰
        
        Returns:
            æ—¶å»¶å€¼ï¼ˆæ¯«ç§’ï¼‰
        """
        # ä¼˜å…ˆä½¿ç”¨æ–°ç‰ˆæ ¼å¼ï¼ˆå·²ç»æ˜¯æ¯«ç§’ï¼‰
        new_key = f"{key_base}_ms"
        if new_key in timing_dict and timing_dict[new_key] is not None:
            return timing_dict[new_key]
        # ä½¿ç”¨æ—§ç‰ˆæ ¼å¼ï¼ˆç§’è½¬æ¯«ç§’ï¼‰
        old_key = key_base
        if old_key in timing_dict and timing_dict[old_key] is not None:
            return timing_dict[old_key] * 1000
        return 0.0

    def load_data(self):
        try:
            with open(self.log_path, 'r') as f:
                self.log_data = json.load(f)
            
            self.steps = self.log_data.get('steps', [])
            if not self.steps:
                st.error("æ—¥å¿—æ–‡ä»¶ä¸ºç©º")
                return

            self.states = []
            self.actions = []
            self.images = [] # å­˜å‚¨ Base64 å­—ç¬¦ä¸²
            self.timings = [] # å­˜å‚¨æ—¶é—´ä¿¡æ¯
            
            for step in self.steps:
                # State
                self.states.append(step.get('input', {}).get('state', []))
                # Action
                action_data = step.get('action', {})
                self.actions.append(action_data.get('values', []))
                # Image
                self.images.append(step.get('input', {}).get('image_base64', None))
                # Timing
                self.timings.append(step.get('timing', {}))
            
            self.states = np.array(self.states)
            self.valid = True
            
        except Exception as e:
            st.error(f"åŠ è½½å¤±è´¥: {e}")
            self.valid = False

    def decode_image(self, b64_str):
        if not b64_str: return None
        try:
            img_data = base64.b64decode(b64_str)
            img_array = np.frombuffer(img_data, dtype=np.uint8)
            img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
            return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        except:
            return None

    def plot_replay_frame(self, step_idx):
        if not self.valid: return

        # è·å–æ•°æ®
        current_state = self.states[step_idx]
        pred_traj = np.array(self.actions[step_idx])
        img = self.decode_image(self.images[step_idx])
        timing = self.timings[step_idx]

        # --- å¸ƒå±€è®¾è®¡ ---
        # ç¬¬ä¸€è¡Œï¼šå·¦ä¾§å›¾åƒï¼Œå³ä¾§3Dè½¨è¿¹
        c1, c2 = st.columns([1, 1.5])
        
        with c1:
            st.markdown("#### ğŸ‘ï¸ æ¨¡å‹è§†è§‰è§‚æµ‹")
            if img is not None:
                st.image(img, caption=f"Step {step_idx} Input (Size: {img.shape})", use_container_width=True)
            else:
                st.warning("æ— å›¾åƒæ•°æ® (æ—§ç‰ˆæ—¥å¿—?)")
            
            # æ˜¾ç¤ºå…³é”®æ—¶å»¶æŒ‡æ ‡ï¼ˆå…¼å®¹æ–°æ—§æ ¼å¼ï¼‰
            if timing:
                t_transport = self._get_latency_ms(timing, 'transport_latency')
                t_infer = self._get_latency_ms(timing, 'inference_latency')
                total = self._get_latency_ms(timing, 'total_latency')
                
                st.markdown("#### â±ï¸ æ—¶å»¶è¯Šæ–­")
                col_t1, col_t2, col_t3 = st.columns(3)
                col_t1.metric("ä¼ è¾“å»¶è¿Ÿ", f"{t_transport:.0f} ms", help="å®¢æˆ·ç«¯æ‹ç…§ -> æœåŠ¡å™¨æ¥æ”¶")
                col_t2.metric("æ¨ç†è€—æ—¶", f"{t_infer:.0f} ms", help="æ¨¡å‹å‰å‘ä¼ æ’­æ—¶é—´")
                col_t3.metric("æ€»å›è·¯", f"{total:.0f} ms", help="æ‹ç…§ -> æ”¶åˆ°åŠ¨ä½œ")
                
                if t_transport > 100:
                    st.error(f"âš ï¸ ä¼ è¾“å»¶è¿Ÿè¿‡é«˜ ({t_transport:.0f}ms)! æ£€æŸ¥ç½‘ç»œæˆ– SSH éš§é“")
                
                # æ˜¾ç¤ºè¯¦ç»†æ—¶é—´æˆ³ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if timing.get('client_send') is not None:
                    st.markdown("#### ğŸ“Š è¯¦ç»†æ—¶é—´çº¿")
                    with st.expander("å±•å¼€æŸ¥çœ‹æ—¶é—´æˆ³è¯¦æƒ…"):
                        if timing.get('client_send'):
                            st.text(f"å®¢æˆ·ç«¯å‘é€: {timing.get('client_send', 'N/A')}")
                        if timing.get('server_recv'):
                            st.text(f"æœåŠ¡å™¨æ¥æ”¶: {timing.get('server_recv', 'N/A')}")
                        if timing.get('infer_start'):
                            st.text(f"æ¨ç†å¼€å§‹: {timing.get('infer_start', 'N/A')}")
                        if timing.get('infer_end'):
                            st.text(f"æ¨ç†ç»“æŸ: {timing.get('infer_end', 'N/A')}")
                        if timing.get('send_timestamp'):
                            st.text(f"å‘é€æ—¶é—´: {timing.get('send_timestamp', 'N/A')}")
                        if timing.get('message_interval_ms') is not None:
                            st.text(f"æ¶ˆæ¯é—´éš”: {timing.get('message_interval_ms', 'N/A'):.1f} ms")

        with c2:
            st.markdown("#### ğŸ—ºï¸ 3D åŠ¨ä½œè§„åˆ’")
            fig = plt.figure(figsize=(8, 6))
            ax = fig.add_subplot(111, projection='3d')
            
            # ç”»å†å²è½¨è¿¹ (æœ€è¿‘50æ­¥)
            start = max(0, step_idx - 50)
            hist = self.states[start:step_idx+1]
            if len(hist) > 1:
                ax.plot(hist[:,0], hist[:,1], hist[:,2], 'k-', alpha=0.3, label='History')
            
            # ç”»å½“å‰ç‚¹
            ax.scatter(current_state[0], current_state[1], current_state[2], c='b', s=100, label='Current')
            
            # ç”»é¢„æµ‹
            if len(pred_traj) > 0:
                ax.plot(pred_traj[:,0], pred_traj[:,1], pred_traj[:,2], 'r--', linewidth=2, label='Pred')
                ax.scatter(pred_traj[-1,0], pred_traj[-1,1], pred_traj[-1,2], c='r', marker='x')

            ax.set_xlabel('X')
            ax.set_ylabel('Y')
            ax.set_zlabel('Z')
            ax.legend()
            
            # å›ºå®šåæ ‡è½´é˜²æ­¢æŠ–åŠ¨
            margin = 0.1
            ax.set_xlim(self.states[:,0].min()-margin, self.states[:,0].max()+margin)
            ax.set_ylim(self.states[:,1].min()-margin, self.states[:,1].max()+margin)
            ax.set_zlim(self.states[:,2].min()-margin, self.states[:,2].max()+margin)
            
            st.pyplot(fig)
            plt.close(fig)

    def plot_latency_analysis(self):
        if not self.timings:
            st.warning("å½“å‰æ—¥å¿—ä¸åŒ…å«æ—¶å»¶æ•°æ®")
            return
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–°ç‰ˆæˆ–æ—§ç‰ˆæ ¼å¼çš„æ—¶å»¶æ•°æ®
        has_new_format = any('inference_latency_ms' in t for t in self.timings)
        has_old_format = any('inference_latency' in t and 'inference_latency_ms' not in t for t in self.timings)
        
        if not (has_new_format or has_old_format):
            st.warning("å½“å‰æ—¥å¿—ä¸åŒ…å«è¯¦ç»†æ—¶å»¶æ•°æ®")
            return

        steps = range(len(self.timings))
        # å…¼å®¹æ–°æ—§æ ¼å¼ï¼šä½¿ç”¨è¾…åŠ©å‡½æ•°å®‰å…¨è·å–æ—¶å»¶å€¼
        trans_lats = [self._get_latency_ms(t, 'transport_latency') for t in self.timings]
        infer_lats = [self._get_latency_ms(t, 'inference_latency') for t in self.timings]
        total_lats = [self._get_latency_ms(t, 'total_latency') for t in self.timings]

        fig, ax = plt.subplots(figsize=(12, 5))
        ax.plot(steps, total_lats, color='gray', alpha=0.3, label='Total Loop')
        ax.plot(steps, trans_lats, color='orange', label='Transport (Network)')
        ax.plot(steps, infer_lats, color='blue', label='Inference (GPU)')
        
        ax.set_title("æ—¶å»¶ç»„æˆåˆ†æ (ms)")
        ax.set_xlabel("Step")
        ax.set_ylabel("Latency (ms)")
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # æ·»åŠ é˜ˆå€¼çº¿
        ax.axhline(100, color='r', linestyle='--', alpha=0.5)
        ax.text(0, 105, '100ms Alert', color='r', fontsize=8)
        
        st.pyplot(fig)
        plt.close(fig)
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        if total_lats:
            col1, col2, col3, col4 = st.columns(4)
            col1.metric("å¹³å‡æ€»å»¶è¿Ÿ", f"{np.mean(total_lats):.1f} ms")
            col2.metric("å¹³å‡ä¼ è¾“å»¶è¿Ÿ", f"{np.mean(trans_lats):.1f} ms")
            col3.metric("å¹³å‡æ¨ç†å»¶è¿Ÿ", f"{np.mean(infer_lats):.1f} ms")
            col4.metric("æœ€å¤§æ€»å»¶è¿Ÿ", f"{np.max(total_lats):.1f} ms")

# --- Main ---
st.set_page_config(layout="wide", page_title="Inference Debugger")
st.title("ğŸ”¬ æ¨ç†æ·±åº¦è¯Šæ–­å·¥å…·")

log_dir = Path(__file__).parent.parent / "realworld_deploy" / "server" / "log"
log_files = sorted(list(log_dir.glob("inference_log_*.json")), key=lambda x: x.stat().st_mtime, reverse=True)

if log_files:
    selected_file = st.sidebar.selectbox("é€‰æ‹©æ—¥å¿—", log_files, format_func=lambda x: x.name)
    if 'gui' not in st.session_state or st.session_state.get('last_log') != selected_file:
        st.session_state.gui = InferenceGUI(str(selected_file))
        st.session_state.last_log = selected_file
else:
    st.error("æœªæ‰¾åˆ°æ—¥å¿—æ–‡ä»¶")

if 'gui' in st.session_state and st.session_state.gui.valid:
    gui = st.session_state.gui
    
    tab1, tab2 = st.tabs(["ğŸ“º é€å¸§å›æ”¾ (Visual & Action)", "ğŸ“ˆ æ€§èƒ½åˆ†æ (Latency)"])
    
    with tab1:
        idx = st.slider("Step", 0, len(gui.steps)-1, 0)
        gui.plot_replay_frame(idx)
        
    with tab2:
        gui.plot_latency_analysis()